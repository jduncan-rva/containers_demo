:toc: left
:icons:
:iconsdir: http://people.redhat.com/~jduncan/images/icons
:imagesdir: http://people.redhat.com/~jduncan/images
:toc-title: Agenda
:toclevels: 3
:sectnums:
:source-highlighter: prettify
:docinfo1:

= USCBP Container Workshop
Jamie Duncan <jduncan@redhat.com>; Tariq Islam <tislam@redhat.com>

== Container Key Concepts

=== Presentation

link:http://redhat.slides.com/jduncan/uscbp-201602/fullscreen[Link to presentation on slides.com]

== Container ulimit and cgroup defaults

As of RHEL Atomic Host 7.1.2, which rebased to docker 1.6.0, the following options are available

=== Per-Container CGroup settings

[quote,RHEL 7.1 Release Notes,https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/7.1_Release_Notes/chap-Red_Hat_Enterprise_Linux-7.1_Release_Notes-Linux_Containers_with_Docker_Format.html]
____
This release adds support for custom cgroups. Using the `--cgroup-parent flag`, you can pass a specific cgroup to run a container in. This allows you to create and manage cgroups on their own. You can define custom resources for those cgroups and put containers under a common parent group.This release adds support for custom cgroups. Using the --cgroup-parent flag, you can pass a specific cgroup to run a container in. This allows you to create and manage cgroups on their own. You can define custom resources for those cgroups and put containers under a common parent group.
____

=== Default ulimit Settings

[quote,RHEL 7.1 Release Notes,https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/7.1_Release_Notes/chap-Red_Hat_Enterprise_Linux-7.1_Release_Notes-Linux_Containers_with_Docker_Format.html]
____
With this update, you can now specify the default ulimit settings for all containers, when configuring the Docker daemon. For example:

`docker -d --default-ulimit nproc=1024:2048docker -d --default-ulimit nproc=1024:2048`

This command sets a soft limit of 1024 and a hard limit of 2048 child processes for all containers. You can set this option multiple times for different ulimit values, for example:

`--default-ulimit nproc=1024:2408 --default-ulimit nofile=100:200`

These settings can be overwritten when creating a container as such:

`docker run -d --ulimit nproc=2048:4096 httpd`
____

=== Release Notes

link:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/7.2_Release_Notes/atomic_host_and_containers.html[RHEL 7.2 Atomic Host Release Notes]

== Atomic Host Key Concepts

[quote,RHEL Atomic Host 7 Getting Started Guide,https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/getting-started-guide/ ]
____
Red Hat Enterprise Linux Atomic host is a variation of Red Hat Enterprise Linux 7 optimized to run Linux containers in the Docker format. It has been designed to take advantage of the powerful technology available in Red Hat Enterprise Linux 7.

Red Hat Enterprise Linux Atomic Host uses SELinux to provide strong safeguards in multi-tenant environments, and provides the ability to perform atomic upgrades and rollbacks, enabling quicker and easier maintenance with less downtime. Red Hat Enterprise Linux Atomic Host uses the same upstream projects delivered via the same RPM packaging as Red Hat Enterprise Linux 7.
____

=== Atomic Upgrades and Downgrades

OSTree and rpm-OSTree - These projects provide atomic upgrades and the ability to roll back upgrades.

=== docker and kubernetes Pre-installed

designed to support modern Linux Containers from the outset

=== SELinux enabled by default

Enabled by default to provide complete multi-tenant security. Youâ€™ll also find Integrity Measurement Architecture (IMA), audit and libwrap available from systemd.

=== Only Two Writeable Directories

There are only two writable directories for local system configuration: /etc/ and /var/. The /usr/ directory is mounted read-only. Other directories are symlinks to a writable location. For example, the /home/ directory is a symlink to the /var/home/ directory.

=== LVM Configured for Container Performance

The default partitioning dedicates most of the available space for the containers, using direct LVM instead of the default loopback.

== Kubernetes Key Concepts

=== Master

=== Node

=== Pod

=== Service

=== Replication Controller

== Kubernetes Lab

=== Lab Topology
We will be using 3 kvm virtual machines on my laptop for today's demonstrations.

[.striped]
|===
|Server Name|IP|Notes|CPUS|RAM|Disk

|laptop|192.168.122.1|Ansible Server/Hypervisor/NFS Server|8 Cores|16GB|256GB SSD

|kube0.example.com|192.168.122.210|Kubernetes Master|2 VCPU|4GB|40GB

|kube1.example.com|192.168.122.211|Kubernetes Node|2 VCPUs|4GB|40GB

|kube2.example.com|192.168.122.212|Kubernetes Node|2 VCPUs|4GB|40GB

|===

=== Kubernetes Cluster Systems

All three nodes are RHEL Atomic Hosts, registered and updated with the latest release of the Operating System.

[source,bash]
.register each node
----
-bash-4.2# subscription-manager register --auto-attach --username=rhn-support-jduncan
----

[source,bash]
.update each node to the latest available RHEL Atomic Image
----
-bash-4.2# atomic host upgrade
Updating from: rhel-atomic-host-ostree:rhel-atomic-host/7/x86_64/standard
...
----

[source,bash]
.reboot each node to boot into the new image
----
-bash-4.2# systemctl reboot
----

=== NFS Server

In this demo, my laptop will be acting as a simple NFS server for the containers to use for persistent and shared storage

[source,bash]
. nfs exports for demo
----
~$ showmount -e 192.168.122.1
Export list for 192.168.122.1:
/var/registry-data 192.168.122.0/24
/var/certs         192.168.122.0/24
----

=== Deploying Kubernetes with Ansible

The Atomic Host default configuration is designed to run as a single-node kubernetes master/node. To cluster them together we alter a few files on each host. This will be done with an Ansible Playbook for our demonstration. This playbook is far from optimized. It has been left with most values hard-coded so new users can more easily see how it is doing work. They can then take that knowledge and improve on the initial design.

`dnf install ansible` was the only requirement on my laptop that I am aware of.

==== Defining Kubernetes Hosts on the Ansible Server

[source,bash]
.edit or create /etc/ansible/hosts on your Ansible Server
----
[kube-masters]
kube0.example.com

[kube-nodes]
kube1.example.com
kube2.example.com
----

[source,bash]
.ensure these hostnames are either controlled by DNS or are in /etc/hosts for your Ansible server
----
~$ cat /etc/hosts
127.0.0.1		localhost.localdomain localhost
::1		localhost6.localdomain6 localhost6
...
192.168.122.210	kube0.example.com
192.168.122.211	kube1.example.com
192.168.122.212	kube2.example.com
----

==== Deploying Kubernetes via Ansible

The Ansible Playbooks, along with this Agenda in raw asciidoc, are available on link:https://github.com/jduncan-rva/containers_demo[GitHub] for continued exploration.

[source,bash]
.deploy our playbook.
----
~$ ansible-playbook kube_3_node_demo.yaml
----

This will take a few minutes and produce a LOT of STDOUT. In the end, green and yellow is good, and red is bad. Any errors should be straight-forward.

[IMPORTANT]
Make sure each host is reachable via ssh-key from the Ansible server before attempting a deployment.

=== Creating a Container Registry

[IMPORTANT]
Atomic Enterprise Platform, as well as OpenShift Enterprise, have an integrated Secure Registry component. Satellite 6 can also act as a container registry and integrate into workflows. For this demo we will be using a simple upstream registry from Docker Hub.

==== Pull the Registry Base Image

[source,bash]
----
-bash-4.2# docker pull registry:2 on each node
...
Status: Downloaded newer image for docker.io/registry:2
----

[TIP]
If you do not do this now, your deploys will still work. Kubernetes will just tell docker to pull the image as needed on the nodes as it creates the pods. This 'priming the pump' will just save time and a little confusion down the road.

==== TLS Setup

For the docker-registry application, if you want to move containers from one host to another, you have to use TLS. This requires a little set up on the kubernetes nodes as well as my laptop (if I want to push images from there as well). For this example, we'll be using a self-signed certificate.

[source,bash]
.create a self-signed certificate on your system
----
~$ mkdir -p certs && openssl req \
  -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \
  -x509 -days 365 -out certs/domain.crtmkdir -p certs && openssl req \
  -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \
  -x509 -days 365 -out certs/domain.crt
----

[source,bash]
.copy the certificate into /etc/docker/certs.d/kube1.example.com:5000/ca.crt on each host that will use this registry
----
$ sudo mkdir -p /etc/docker/certs.d/kube1.example.com:5000
$ cp ~/certs/domain.crt /etc/docker/certs.d/kube1.example.com:5000/ca.crt
----

[source,bash]
.restart the docker service so it will recognize the new certificate on each host that will use the registry
----
$ sudo systemctl restart docker.service
----

==== Kubernetes node Setup for TLS

For this example we are going to use /var/certs on each host to present the certificates to the docker registry container. This could also be used with NFS, iSCSI or other solutions, but this is the most straightforward for this example.

This deploy work has already been done by our Ansible playbook.

==== Create a kubernetes Pod for the registry

[source,bash]
.create registry-service.yaml on the master
----
apiVersion: v1
kind: Service
metadata:
  labels:
    name: registry
  name: registry-service
  namespace: default
spec:
  ports: [
    { "name": "web-registry",
      "protocol": "TCP",
      "port": 5000,
      "targetPort": 5000
    }
  ]
  selector:
    name: registry
  deprecatedPublicIPs:
  - 192.168.122.211
  - 192.168.122.212
----

[source,bash]
.create the registry service
----
-bash-4.2# kubectl create -f regsitry-service.yaml
services/registry-service
----

[source,bash]
.confirm it was created
----
-bash-4.2# kubectl get services
NAME               LABELS                                    SELECTOR        IP(S)           PORT(S)
kubernetes         component=apiserver,provider=kubernetes   <none>          10.254.0.1      443/TCP
registry-service   name=registry                             name=registry   10.254.144.95   5000/TCP
----

[source,bash]
.create registry-controller.yaml
----
kind: ReplicationController
apiVersion: v1
metadata:
  name: registry-rc
  labels:
    name: registry-rc
spec:
  replicas: 1
  selector:
    name: registry
  template:
    metadata:
      labels:
        name: registry
    spec:
      containers:
      - name: registry
        image: docker.io/registry:2
        volumeMounts:
        - mountPath: "/var/certs:z" # <1>
          name: certdir
        env:
          - name: REGISTRY_HTTP_TLS_CERTIFICATE
            value: /var/certs/domain.crt
          - name: REGISTRY_HTTP_TLS_KEY
            value: /var/certs/domain.key
        ports:
          - name: reg-port
            containerPort: 5000
      volumes:
        - name: certdir
          hostPath:
            path: "/var/certs"
----
<1> The :z flag handles all of the SELinux magic between the host and the container

[source,bash]
.create the registry replication controller
----
-bash-4.2# kubectl create -f registry-controller.yaml
----

[source,bash]
.confirm the rc and pod has been created
----
-bash-4.2# kubectl get rc
CONTROLLER            CONTAINER(S)   IMAGE(S)     SELECTOR        REPLICAS
registry-controller   registry       registry:2   name=registry   1
-bash-4.2# kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
registry-controller-m4wwq   1/1       Running   0          4m
----

==== Access the Registry

At this point, we should be able to push an image into our registry from any host that has the CA's certificate installed

[source,bash]
.push an image into our new registry
----
~$ sudo docker tag docker.io/jeduncan/soscleaner kube1.example.com:5000/soscleaner
~$ sudo docker push kube1.example.com:5000/soscleaner
----

[source,bash]
.confirm that we have pushed the image up
----
~$ curl --insecure https://kube1.example.com:5000/v2/_catalog
{"repositories":["soscleaner"]}
----

==== Stateless without Persistent Storage

What happens if you replace the pod for any reason with this configuration?

===== Make Kubernetes Restart the Pod

[source,bash]
.find the current container
----
-bash-4.2# docker ps
CONTAINER ID        IMAGE                                  COMMAND                  CREATED              STATUS              PORTS               NAMES
2b2672902ded        docker.io/registry:2                   "/bin/registry /etc/d"   10 seconds ago       Up 8 seconds                            k8s_registry.aa845cc4_registry-rc-8612o_default_b12a6f88-d03d-11e5-81d9-525400a7840e_3787984f
92436e44ef56        gcr.io/google_containers/pause:0.8.0   "/pause"                 About a minute ago   Up About a minute                       k8s_POD.64debde_registry-rc-8612o_default_b12a6f88-d03d-11e5-81d9-525400a7840e_ccaeb605
----

[source,bash]
.remove the current container
-bash-4.2# docker rm -f 2b2672902ded
2b2672902ded
----

[source,bash]
.confirm that a new container was created for the pod
----
-bash-4.2# docker ps
CONTAINER ID        IMAGE                                  COMMAND                  CREATED              STATUS              PORTS               NAMES
15474080fcc8        docker.io/registry:2                   "/bin/registry /etc/d"   About a minute ago   Up About a minute                       k8s_registry.aa845cc4_registry-rc-8612o_default_b12a6f88-d03d-11e5-81d9-525400a7840e_7317d54a
92436e44ef56        gcr.io/google_containers/pause:0.8.0   "/pause"                 3 minutes ago        Up 3 minutes                            k8s_POD.64debde_registry-rc-8612o_default_b12a6f88-d03d-11e5-81d9-525400a7840e_ccaeb605
----

[source,bash]
.look for our uploaded container image again
----
~$ curl --insecure https://kube1.example.com:5000/v2/_catalog
{"repositories":[]}

----

==== Adding Persistent Storage with High Availability

Like we just saw, containers are considered 'ephemeral'. When a container is replaced for any reason, it is replaced, not recovered.

[TIP]
The data is (necessarily) gone. The ephemeral filesystem is still on the host(s) it was running on before it was removed/stopped responding/$whatever. So you can run diagnostics and run forensics. But building that into your workflow is not the goal here.

To provide persistent storage, we will create a new replication controller that uses NFS for container registry storage.

[source,bash]
. our new controller
----
kind: ReplicationController
apiVersion: v1
metadata:
  name: registry-rc
  labels:
    name: registry-rc
spec:
  replicas: 1
  selector:
    name: registry
  template:
    metadata:
      labels:
        name: registry
    spec:
      containers:
      - name: registry
        image: docker.io/registry:2
        volumeMounts:
        - mountPath: "/var/certs"
          name: certdir
        - mountPath: "/var/lib/registry/docker"
          name: registrydir
        env:
          - name: REGISTRY_HTTP_TLS_CERTIFICATE
            value: /var/certs/domain.crt
          - name: REGISTRY_HTTP_TLS_KEY
            value: /var/certs/domain.key
        ports:
          - name: reg-port
            containerPort: 5000
      volumes:
        - name: certdir
          nfs:
            path: "/var/certs"
            server: 192.168.122.1
            readOnly: True
        - name: registrydir
          nfs:
            path: "/var/registry-data"
            server: 192.168.122.1
----

[source,bash]
.we remove the old replication controller
----
-bash-4.2# kubectl delete rc registry-rc
----

[source,bash]
.and create our new one with our nfs-based config
----
-bash-4.2# kubectl create -f registry-controller-nfs.yaml
----

[source,bash]
.confirm our new rc is created
----
-bash-4.2# kubectl get pods
NAME                READY     STATUS    RESTARTS   AGE
registry-rc-13zln   1/1       Running   0          39s
----

===== Re-uploading our image

[source,bash]
.we upload our container image ... again
----
~$ sudo docker push kube1.example.com:5000/soscleaner
The push refers to a repository [kube1.example.com:5000/soscleaner] (len: 1)
...
latest: digest: sha256:00fc342d4a42352d2349045f144555f0e0ed30c81d8e27ada1af5c71238e02d1 size: 15829
----

[source,bash]
.blow away our container again
----
-bash-4.2# kubectl delete rc registry-rc
replicationcontrollers/registry-rc
----

[source,bash]
.confirm there are no pods up and running
----
-bash-4.2# kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
----

[source,bash]
.re-create our nfs replication controller
----
-bash-4.2# kubectl create -f registry-controller-nfs.yaml
replicationcontrollers/registry-rc
----

[source,bash]
.confirm that it is up and running
----
-bash-4.2# kubectl get pods
NAME                READY     STATUS    RESTARTS   AGE
registry-rc-f21ku   1/1       Running   0          45s
----

[source,bash]
.look to see if we still have our container image available
----
jduncan@dhcp-192-168-1-140 uscbp_containers$ curl --insecure https://kube1.example.com:5000/v2/_catalog
{"repositories":["soscleaner"]}
----

[source,bash]
.pull it down to another host
----
-bash-4.2# docker pull kube1.example.com:5000/soscleaner
Using default tag: latest
Trying to pull repository kube1.example.com:5000/soscleaner ... latest: Pulling from soscleaner
00a0c78eeb6d: Pull complete
834629358fe2: Pull complete
052ba2d31c49: Pull complete
c89867de8092: Pull complete 
361b059cb076: Pull complete
c4c9372b59a3: Pull complete
84587fefdc90: Pull complete
e98320e5d16a: Pull complete
511136ea3c5a: Already exists
Digest: sha256:00fc342d4a42352d2349045f144555f0e0ed30c81d8e27ada1af5c71238e02d1
Status: Downloaded newer image for kube1.example.com:5000/soscleaner:latest

-bash-4.2# docker images
REPOSITORY                          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
docker.io/registry                  2                   cc4e7e4415c5        6 days ago          165.6 MB
kube1.example.com:5000/soscleaner   latest              e98320e5d16a        10 months ago       256.6 MB
gcr.io/google_containers/pause      0.8.0               2c40b0526b63        10 months ago       241.7 kB
----
