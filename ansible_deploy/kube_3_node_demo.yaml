- hosts: all
  # This included vars_files (passes.yml) need to contain a variable named 'rhn_pass' that is your RHN password for registration of the nodes
  # It is HIGHLY recommended that you use ansible-vault to protect this data on your system.
  # See http://docs.ansible.com/ansible/playbooks_vault.html for more information.
  vars_files:
    - passes.yml
  remote_user: root
  tasks:
  - redhat_subscription: state=present username={{ rhn_user }} password={{ rhn_pass }} autosubscribe=true
  - name: Check for an Atomic Host upgrade
    command: atomic host upgrade
  - name: reboot each box
    shell: sleep 2 && systemctl reboot
    async: 1
    poll: 0
    ignore_errors: true
  - name: wait for server to come back
    local_action: wait_for host={{ inventory_hostname }} state=started delay=30 timeout=300 port=22
    sudo: false

- hosts: kube-masters
  vars_files:
  - vars.yml
  remote_user: root
  tasks:
  - name: configure /etc/resolv.conf
    template: src=templates/resolv_conf.j2 dest=/etc/resolv.conf
  - name: configure /etc/hosts
    template: src=templates/hosts_file.j2 dest=/etc/hosts
  - name: configure /etc/etcd/etcd.conf for master
    template: src=templates/etcd_conf_master.j2 dest=/etc/etcd/etcd.conf
  - name: configure /etc/kubernetes/config for master
    template: src=templates/kubernetes_config.j2 dest=/etc/kubernetes/config
  - name: configure /etc/kubernetes/apiserver for master
    template: src=templates/kubernetes_apiserver_master.j2 dest=/etc/kubernetes/apiserver
  - name: restart and enable etcd on master
    service: name=etcd state=restarted enabled=yes
  - name: restart and enable kube-apiserver service on master
    service: name=kube-apiserver state=restarted enabled=yes
  - name: restart and enable kube-controller-manager service on master
    service: name=kube-controller-manager state=restarted enabled=yes
  - name: restart and enable kube-scheduler on master
    service: name=kube-scheduler state=restarted enabled=yes
  - name: create flannel-config.json on master
    template: src=templates/flannel-config.json dest=/root/flannel-config.json
  - name: set flannel config in etcd database on master
    command: curl -L http://kube0.example.com:2379/v2/keys/coreos.com/network/config -XPUT --data-urlencode value@/root/flannel-config.json
  - name: configure flannel
    template: src=templates/sysconfig_flanneld.j2 dest=/etc/sysconfig/flanneld
  - name: restart and enable flanneld
    service: name=flanneld state=restarted enabled=yes
  - name: create kubernetes template for registry service
    template: src=templates/registry-service.yaml dest=/root/registry-service.yaml
  - name: create kubernetes template for registry replication controller
    template: src=templates/registry-controller.yaml dest=/root/registry-controller.yaml
  - name: create kubernetes template for registry replication controller with nfs
    template: src=templates/registry-controller-nfs.yaml dest=/root/registry-controller-nfs.yaml

- hosts: kube-nodes
  vars_files:
  - vars.yml
  remote_user: root
  tasks:
  - name: configure /etc/resolv.conf
    template: src=templates/resolv_conf.j2 dest=/etc/resolv.conf
  - name: configure /etc/hosts
    template: src=templates/hosts_file.j2 dest=/etc/hosts
  - name: configure /etc/kubernetes/config on node
    template: src=templates/kubernetes_config.j2 dest=/etc/kubernetes/config
  - name: configure /etc/kubernetes/kubelet on node
    template: src=templates/kubernetes_kubelet_node.j2 dest=/etc/kubernetes/kubelet
  - name: configure /etc/kubernets/proxy on node
    template: src=templates/kubernetes_proxy_node.j2 dest=/etc/kubernetes/proxy
  - name: restart and enable docker on node
    service: name=docker state=restarted enabled=yes
  - name: restart and enable kube-proxy on node
    service: name=kube-proxy state=restarted enabled=yes
  - name: restart and enable kubelet on node
    service: name=kubelet state=restarted enabled=yes
  - name: configure flannel
    template: src=templates/sysconfig_flanneld.j2 dest=/etc/sysconfig/flanneld
  - name: restart and enable flanneld
    service: name=flanneld state=restarted enabled=yes
  - name: create the certificate directory for each node
    file: path=/etc/docker/certs.d/kube1.example.com:5000 state=directory
  - name: add the registry certificate for docker
    template: src=templates/certs/domain.crt dest=/etc/docker/certs.d/kube1.example.com:5000/ca.crt
  - name: create the certs directory to mount into the registry container
    file: path=/var/certs state=directory
  - name: add the registry cert to /var/certs
    template: src=templates/certs/domain.crt dest=/var/certs/domain.crt
  - name: add the registry key to /var/certs
    template: src=templates/certs/domain.key dest=/var/certs/domain.key
  - name: set selnux boolean to allow pods to use nfs
    command: /usr/sbin/setsebool -P virt_use_nfs 1

- hosts: all
  remote_user: root
  tasks:
    - name: reboot each box
      shell: sleep 2 && systemctl reboot
      async: 1
      poll: 0
      ignore_errors: true
    - name: wait for server to come back
      local_action: wait_for host={{ inventory_hostname }} state=started delay=30 timeout=300 port=22
      sudo: false

- hosts: kube-nodes
  remote_user: root
  tasks:
    - name: pull registry v2 docker image
      command: docker pull docker.io/registry:2

- hosts: kube-masters
  remote_user: root
  vars_files:
  - vars.yml
  tasks:
    - name: create a kubernetes service for the registry
      command: kubectl create -f /root/registry-service.yaml
      when: provision_demo
    - name: create an nfs-based replication controller
      command: kubectl create -f /root/registry-controller-nfs.yaml
      when: provision_demo and provision_with_nfs
    - name: create a local-storage based replication controller
      command: kubectl create -f /root/registry-controller.yaml
      when: provision_demo and not provision_with_nfs
